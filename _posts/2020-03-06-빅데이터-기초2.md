---
date: 2020-03-06 24:00:00
layout: post
title: 빅데이터-기초2
subtitle: 기초이론 공부
description: 빅데이터에 대한 기초이론을 공부를 해보자
image: https://res.cloudinary.com/dm7h7e8xj/image/upload/v1559822137/theme11_vei7iw.jpg
optimized_image: https://res.cloudinary.com/dm7h7e8xj/image/upload/c_scale,w_380/v1559822137/theme11_vei7iw.jpg
category: project
tags:
  - 빅데이터
  - 파이썬
  - 기초
  - 데이터마이닝
author: 김대훈
---

## 🎤 프로젝트 소개

빅데이터 기초이론학습

## 🎤 빅데이터 기초이론학습2

EM Clustering

> Probabilistic Modeling for Generating Documents

- Generative model (생성 모델)
  - A Model for randomly generation observable data based on hidden parameters
- 내가 가진 데이터를 생성했을 확률이 제일 높은 것 > Likelihood
- Likelihood가 제일 높은 모델을 선택하는 것 > Probabilistic Modeling

> EM Algorithm

- **Maximum Likelihood**를 만들기위한 알고리즘 > 식 구함 > 식이 사이클로 나타남

> EM Clustering Algorithm

- Cluster 생성 모델을 역으로 찾기
  - 모델마다 세개의 상수 찾기 > 평균점, 표준편차, 모델이 선택될 확률
  - K개의 Cluster > 3K 개의 상수를 찾기
- log를 취한 Likelihood > Log Likelihood

- E-Step for Em Clustering Algorithm
  - 각 데이터들에 대해서 클러스터에 속할 확률을 구함
- M-Step for Em Clustering Algorithm

  - 모든 데이터에 대해서 어느 클러스터에 포함되는지 확률값을 계산
  - 각 클러스터 데이터 점들을 이용해 Likelihood를 가지는 매개 변수들을 재 계산

- [EM Clustering Algorithm]

  1. E-Step의 값이 M-Step에 사용되고 M-Step 값이 E-Step에 사용 > 사이클 존재
  2. 처음엔 찾아야하는 파라메터에 랜덤 값 적용
  3. 계속 사이클대로 계산
  4. 값들이 더 이상 변하지않고 수렴
  5. 각 수렴 값 => 각 파라메터 값

* EM Clustering 이 강력한 Clustering인 이유
  - 제대로 하는 Clustering
    1. 생성모델 생성
    2. 생성모델 파라메터 구함
    3. 클러스터링 확률 계산
    4. 포인트마다 가장 확률이 높은 클러스터 구함

> PLSI (Probabilistic Latent Semantic Indexing)

- 단어 하나하나 주제 선택 (앞에선 데이터가 있으면 클러스터가 바로 결정)
- Likelihood Function for Em Algorithm
- EM Clustering Algorithm 보다 주제가 있는 좀더 복잡한 알고리즘
- Problem Formulation
- LiKelihood Function

# Recommendation Systems

> Content based filtering method

    - item이나 product등과 같은 actual content를 이용함
    - 각 item간의 similarity를 이용해서 추천함

> Collaborative filtering method

    - 각각의 유저는 비슷한 다른 유저와 동일하게 행동한다는 가정 - 다른 유저들이 추천에영향을 끼침
    - User가 **직접 점수를 매긴** item들에 대한 rating 을 이용해서 추진
    - Memory based method
        - 과거의 rating에 base해서 rating prediction을 함
    - Model based method
        - 과거의 rating에 base해서 model을 만들고 그 모델에 의해서 unseen item이 rating을 함

> Matrix Factorization

    - 영화추천 유저가 평점을 매겨둔 매트릭스 찾기
       1. 유저가 모든 영화를 다 볼 수 없으니 대부분 빔
       2. 두 매트릭스의 곱이 평점 매트릭스의 값과 유사하게 되는 두 매트릭스 구하기
          *Matrix Factorization 역할 : [user x k] x [k x item] 가 유저가 평점을 매겨둔 매트릭스와 거의 같도록 하는 `[user x k]`, `[k x item]` 매트릭스 찾기
       3. 곱으로 비워진 부분이 채워지면 > `예상 평점`
       4. 곱으로 채워진 값 중 가장 높은 값 > `추천`
    - Matrix factorization is inrtoduced because of sparsity of real data
      - Improving Matrix Factorization with PLSI > 더 나은 추천을 위해 rating정보 외 텍스트 정보도 저장
