---
date: 2020-03-09 24:00:00
layout: post
title: 인공지능-기초1
subtitle: 기초이론 공부
description: 인공지능에 대한 기초이론을 공부를 해보자
image: https://res.cloudinary.com/dm7h7e8xj/image/upload/v1559822137/theme11_vei7iw.jpg
optimized_image: https://res.cloudinary.com/dm7h7e8xj/image/upload/c_scale,w_380/v1559822137/theme11_vei7iw.jpg
category: project
tags:
  - 인공지능
  - 학습
  - 기초
  - 데이터마이닝
author: 김대훈
comments: true
---

## 🎤 프로젝트 소개

인공지능 기초이론학습1

## 🎤 인공지능 기초이론

# 1. AL, ML, and Related Areas

    어떠한 점이 서로 다른지 비교

> ML vs. Big Data

    -ML : 빅데이터를 분석하고, 이해하고, 예측하는 방법론 중 하나

> ML vs. Data Mining

    -Data Mining은 정형 데이터(structured data)를 사용

    ex) 정형 데이터 : 사람의 나이, 성별, 거주지 등이 테이블로 나타난 경우

    대표적인 비정형 테이터 : 이미지, 텍스트(뉴스 기사나 블로그 포스팅)

    ML의 장점은 비정형 테이터를 비교할 수 있다는 것

> ML vs. AI

    ML은 AI의 일부분

    AI는 사람의 지능을 컴퓨터도 갖게 하는 것

    그 사람처럼 지능적인 행동을 하는 컴퓨터를 만드는 방법 중

    데이터에 의존하는, 데이터를 통계적으로 분석해서 예측 모델을 만드는 방법이 ML

> ML vs. Statistics

    ML = 밀접한 관계, 통계학을 사용하는 것이

    통계학자들이 몇 십년간 만들어 놓은 다양한 모델을 실생활에 볼 수 있는 데이터에 적용한 것이 ML

    practical limitations을 극복한다는 것 : 통계학에서 다루는 데이터보다 양과 노이즈가 많음,

    데이터가 부분적으로 없거나 훼손된 경우도 있음, ML의 다양한 기법으로 이러한 한계를 극복

# 2. Major Problem Formulations in ML

> Supervised Learning (지도학습)

training data, testing data
이미지로 학습하는 경우, training data의 여러 이미지에는 'car'라는 라벨이 붙어있어서
해당 데이터가 어떤 데이터인지 알려줌 (classification)
그럼 testing data의 여러 이미지를 보고 'car?'라는 물음에
실제 car일 경우 yes, 아닐 경우 no라고 대답 (accuracy를 평가하는 척도)

- classification을 하는 경우, 선형 모델과 비선형 모델이 있음

- decision tree

물건 구매 데이터에서 feature은 item, price, season이 될 수 있음
마지막 데이터(15th transaction)의 빈 곳을 결정해보자
decision tree의 제일 위는 item, 즉 15th trans.는 pantry food, off-season,이므로
internet에서 구매했을 것이다라고 예측이 가능해짐

> Unsupervised Learning (비지도학습)

지도학습은 데이터에 대해 라벨을 갖고 있어야, 정답이 있는 데이터를 구하는 것이 어려움
그래서 비지도 학습을 사용
여러 이미지 중 자동차와 꽃, 나무가 섞여 있음, 비슷한 것을 찾아라? (사람도 그렇듯)
비슷한 특징을 갖고 비슷한 분류일 것으로 추측함

- K-means clustering : 기준이 되는 중간 점을 찾고, 거기에서 각각의 data point까지의 거리를 계산해서 가까운 기준점에 색깔로 데이터를 색칠하는 것
  ex) 2차원 데이터, x는 키, y는 나이, 비슷한 나이에 비슷한 키를 가진 사람 분류하기
  사람이던 사진이던 몇 개의 그룹으로 나눌 것인가? (예시는 5개)
  즉, 가까이 있는 것들은 같은 그룹에 속할 것이다

- DB Scan : 기준이 되는 점을 먼저 찾는게 아니고, 임의의 data point 하나에서 시작해서
  자기한테 가까이 있는 점들로 세력을 늘려나가는 것,
  나머지 data point에서 다시 시작해서 새로운 그룹 생성
  즉, 결과가 어떻게 생겼느냐에 따라 나누는 기준이 달라짐
  데이터의 숨겨진 의미를 잘 찾아내는 알고리즘

> Representation Learning (딥러닝)

Deep Neural Network
1950,60년대 부터 연구하였음, 쓸모없다는 결론이 내려져 한동안 연구되지 않았음
2000년 초반에서 다시 히트침
reducing the demensionality of data with Neural Network
2000년대 부터 data size가 매우 커지면서, demensionality를 줄여야 함(의미가 있는 것만 남김)
그것을 Neural Network로 할 수 있음
ex) facial recognition : 사람의 얼굴을 사진으로 찍어서 이것이 얼굴인지, 얼굴이 몇개인지 찾음
어떠한 부분이 얼굴인지 찾으려면 하나의 픽셀에 대해 RGB값를 찾음
1st layer - 흑백 사진이라면 각 픽셀에 대해 0~266 단계로 나눔
2nd layer - 얼굴의 경계선을 찾고, 눈코입의 선으로 이루어진 것, 픽셀값들로 선 찾기
3rd layer - 2nd layer에서 찾은 선과 곡선의 조합으로 찾은 것이 눈코입
4th layer - 전체 얼굴이 나오게 됨
과거에는 선을 찾는 것을 선 찾기 알고리즘, 곡선 찾기 알고리즘, 타원 찾기 알고리즘 하나하나를 다 만들고, 그 이후에 눈코입 찾는 모델을 만들고, 사람을 찾고 자동차를 찾곤 하였음
즉, Neural Network는 이 모든 과정을 하나로 만들어냄

- 왜 이제서야 쓰이는가?
  complexity of model is very high - 많은 데이터셋을 요구하고, 더 성능 좋은 컴퓨터가 필요
  model is prone to overfitting - 복잡한 모델을 학습시키려면 사람의 직관적 추론보다는 컴퓨터만이 할 수 있는 디테일이 있는 것, dropout과 같은 알고리즘이 있음
  parameter estimation is difficult

# 3. Famous AI Systems

1. IBM에서 나온 Deep Blue, chess machine

2. 자율주행 : 10여년 전부터 연구해왔음
   한정된 상황에서만 주행가능하였음
   2007년부터는 Urban Challenge 실제 환경과 비슷하게 만들어 어느정도 성공함

3. IBM Research Watson 2011

Jeopardy 퀴즈쇼, 자연어로 질문
어려운 점은 유머, 속담 등이 있고, 질문을 꼬아서 내기도 함, 사람의 말을 이해할 수 있어야 했음

4. DeepMind AlphaGo 2016

5. DeepMind AlphaGo Zero 2017

이세돌을 이긴 알파고는 fair하였다고 보기 어려움
사람이 학습할 수 있는 양보다 훨씬 많았기 때문임
하지만, AlphaGo Zero는 학습 데이터가 주어지지 않았음, 스스로와 학습
zero에서 시작한다고 해서 AlphaGo Zero임, basic rule만 제공
3일만 지나면, AlphaGo와 실력이 비슷해 짐
21일이 지났을 때 AlphaGo master라는 새로운 버전은 질 수 없는 버전이 나옴

6. Google Duplex 2018
   naver cloba, samsung bixby와 같은 시스템
   날씨 알려줘, 아재개그 해줘와 같은 범용챗봇이 아니고, 비즈니스 용도
   미용실용 챗봇처럼, 몇 시에 파마 예약해줘, 어떤 걸 하시겠어요, 11시는 안되는데, 11시 반은요?
   이런식으로 대화가 가능하며 비즈니스에 연결됨
   범용 챗봇보다 어려울까?

# Major Domains within AI & Corresponding Datasets

1. Visual Intelligence

- MNIST (숫자 필기 인식) : 가장 쉬운 dataset
- ImageNet : 몇 천개의 class의 이미지 (포유류-강아지-허스키) 처럼 계층구조 존재
  아직도 정확도를 올리는 연구 진행 중, 정확도를 올리면서 data가 적은 class도 정확도를 높이려고 함

2.  Language Intelligence : 지문 정보를 많이 주고, 그에 대해 질문하면 답을 할 수 있는가? QnA
    스탠포드에서 만든 SQUAD Dataset사용, 지문에 답이 없는 경우 답을 찾을 수 없다고 할 수 있어야함

3.  Machine Translation

- Europarl Corpus
  어떤 문서에 대해 문장 단위로 (예를 들어)한국어와 영어로 쓰여있을 때 기계 번역을 쉽게 학습 가능하게 하는 많이 쓰는 방법, European language만 지원
- UN parallel Corpus : 다양한 언어 지원
- GLUE Benchmark : NYU, UWNLP, DeelMind은 더 나아가서 문법적으로 맞는지, 문장을 읽은 후 알 수 있는 것과 알 수 없는 것, 주장하는 것과 그렇지 않은 것처럼 detail한 task 수행 가능
